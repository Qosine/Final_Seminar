#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
# training data
# train.control <- trainControl(method = "cv", number = 10)
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Random Forest
yf = as.factor(train.data[,1]) #IS FIRST COLUMN THE LABEL?
rf.1 <- randomForest(yf ~., data = train.data[,-1] , ntree = 500, importance=T) #CHECK X's
yf = as.factor(test.data[,1])
testSpl = data.frame(yf, test.data)
pred.rf = predict(rf.1, test.data[,-1], type = "prob")[,1]
true_neg = sum(test.data[,1]==0 & pred.rf<0.5)
true_pos = sum(test.data[,1]==1 & pred.rf>0.5)
false_pos = sum(test.data[,1]==0 & pred.rf>0.5)
false_neg = sum(test.data[,1]==1 & pred.rf<0.5)
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =", prediction_accuracy))
data = true_target_variables
library(MASS)
library(caret)
library(dplyr)
# install.packages("pROC")
library(pROC)
# generate_response(predictors, parameters, sample_size)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
corrplot(cor(train_data), type="upper", order="hclust",
sig.level = 0.01, insig = "blank")
# training data
# train.control <- trainControl(method = "cv", number = 10)
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Random Forest
yf = as.factor(train.data[,1]) #IS FIRST COLUMN THE LABEL?
# trnSpl =  data.frame(yf,train.data)
glm.1 <- glm( yf ~ ., data = train.data[,-1], family=binomial(link="logit") )
yf = as.factor(test.data[,1])
testSpl = data.frame(yf, test.data)
pred.glm = predict.glm(glm.1, test.data[,-1], type = "link")
true_neg = sum(test.data[,1]==0 & pred.glm<0)
true_pos = sum(test.data[,1]==1 & pred.glm>0)
false_pos = sum(test.data[,1]==0 & pred.glm>0) # error type I
false_neg = sum(test.data[,1]==1 & pred.glm<0)# error type II
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =",prediction_accuracy))
library(MASS)
library(caret)
library(dplyr)
# install.packages("pROC")
library(pROC)
# generate_response(predictors, parameters, sample_size)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
#corrplot(cor(train_data), type="upper", order="hclust",
#        sig.level = 0.01, insig = "blank")
# training data
# train.control <- trainControl(method = "cv", number = 10)
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Linear Discriminant Analysis
lda.1 <- lda( V1 ~ ., data = train.data )
test.data = as.data.frame(test.data)
true_neg = sum(test.data[,1]==0 & predict(lda.1, test.data)$class==0) # correct predicted "KPI = 0", also called "specificity"
true_pos = sum(test.data[,1]==1 & predict(lda.1, test.data)$class==1) # correct predicted "KPI = 1", also called "sensitivity"
false_pos = sum(test.data[,1]==0 & predict(lda.1, test.data)$class==1) # error type I
false_neg = sum(test.data[,1]==1 & predict(lda.1, test.data)$class==0) # error type II
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =", prediction_accuracy))
# install.packages(neuralnet)
library(neuralnet)
library(MASS)
library(caret)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
# training data
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Neural Network
yf = as.factor(train.data[,1])
nn.1 <- neuralnet(yf ~., data = train.data[,-1], hidden = 3) #training neural net
pred.nn = predict(nn.1, test.data[,-1])[,1]
true_neg = sum(test.data[,1]==0 & pred.nn>0.5)
true_pos = sum(test.data[,1]==1 & pred.nn<0.5)
false_pos = sum(test.data[,1]==0 & pred.nn<0.5)
false_neg = sum(test.data[,1]==1 & pred.nn>0.5)
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =", prediction_accuracy))
target_gender = "Female" # options are "Male", "Female"
target_age = "35-44" # options are "25-34", "35-44", "45-54", "55-99"
kpi = "Consideration" # options are "Familiarity", "Consideration", "Awareness"
################## CHOOSE TARGET GROUP AND KPI ABOVE ##################
#######################################################################
target_min_age = as.numeric(substring(target_age, 1, 2))
target_max_age = as.numeric(substring(target_age, nchar(target_age)-1, nchar(target_age)))
# Load Pointlogic source data
source_data = read.csv("./cleaned_unified_sample.csv")
# Separate true data into predictors and responses, and split target and non-target data
true_fullsample_variables = separate_predictors_responses(source_data)
subsamples = split_sample(source_data, tolower(target_gender), target_min_age, target_max_age)
true_target_variables = separate_predictors_responses(subsamples$target)
true_nontarget_variables = separate_predictors_responses(subsamples$nontarget)
data = true_target_variables
library(randomForest)
library(MASS)
library(caret)
# install.packages(rfUtilities)
library(rfUtilities)
# generate_response(predictors, parameters, sample_size)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
# training data
# train.control <- trainControl(method = "cv", number = 10)
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Random Forest
yf = as.factor(train.data[,1]) #IS FIRST COLUMN THE LABEL?
rf.1 <- randomForest(yf ~., data = train.data[,-1] , ntree = 500, importance=T) #CHECK X's
yf = as.factor(test.data[,1])
testSpl = data.frame(yf, test.data)
pred.rf = predict(rf.1, test.data[,-1], type = "prob")[,1]
true_neg = sum(test.data[,1]==0 & pred.rf<0.5)
true_pos = sum(test.data[,1]==1 & pred.rf>0.5)
false_pos = sum(test.data[,1]==0 & pred.rf>0.5)
false_neg = sum(test.data[,1]==1 & pred.rf<0.5)
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =", prediction_accuracy))
library(MASS)
library(caret)
library(dplyr)
# install.packages("pROC")
library(pROC)
# generate_response(predictors, parameters, sample_size)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
corrplot(cor(train_data), type="upper", order="hclust",
sig.level = 0.01, insig = "blank")
# training data
# train.control <- trainControl(method = "cv", number = 10)
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Random Forest
yf = as.factor(train.data[,1]) #IS FIRST COLUMN THE LABEL?
# trnSpl =  data.frame(yf,train.data)
glm.1 <- glm( yf ~ ., data = train.data[,-1], family=binomial(link="logit") )
yf = as.factor(test.data[,1])
testSpl = data.frame(yf, test.data)
pred.glm = predict.glm(glm.1, test.data[,-1], type = "link")
true_neg = sum(test.data[,1]==0 & pred.glm<0)
true_pos = sum(test.data[,1]==1 & pred.glm>0)
false_pos = sum(test.data[,1]==0 & pred.glm>0) # error type I
false_neg = sum(test.data[,1]==1 & pred.glm<0)# error type II
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =",prediction_accuracy))
library(MASS)
library(caret)
library(dplyr)
# install.packages("pROC")
library(pROC)
# generate_response(predictors, parameters, sample_size)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
#corrplot(cor(train_data), type="upper", order="hclust",
#        sig.level = 0.01, insig = "blank")
# training data
# train.control <- trainControl(method = "cv", number = 10)
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Linear Discriminant Analysis
lda.1 <- lda( V1 ~ ., data = train.data )
test.data = as.data.frame(test.data)
true_neg = sum(test.data[,1]==0 & predict(lda.1, test.data)$class==0) # correct predicted "KPI = 0", also called "specificity"
true_pos = sum(test.data[,1]==1 & predict(lda.1, test.data)$class==1) # correct predicted "KPI = 1", also called "sensitivity"
false_pos = sum(test.data[,1]==0 & predict(lda.1, test.data)$class==1) # error type I
false_neg = sum(test.data[,1]==1 & predict(lda.1, test.data)$class==0) # error type II
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =", prediction_accuracy))
# install.packages(neuralnet)
library(neuralnet)
library(MASS)
library(caret)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
# training data
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Neural Network
yf = as.factor(train.data[,1])
nn.1 <- neuralnet(yf ~., data = train.data[,-1], hidden = 3) #training neural net
pred.nn = predict(nn.1, test.data[,-1])[,1]
true_neg = sum(test.data[,1]==0 & pred.nn>0.5)
true_pos = sum(test.data[,1]==1 & pred.nn<0.5)
false_pos = sum(test.data[,1]==0 & pred.nn<0.5)
false_neg = sum(test.data[,1]==1 & pred.nn>0.5)
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =", prediction_accuracy))
# install.packages(neuralnet)
library(neuralnet)
library(MASS)
library(caret)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
# training data
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Neural Network
yf = as.factor(train.data[,1])
nn.1 <- neuralnet(yf ~., data = train.data[,-1], hidden = 3) #training neural net
pred.nn = predict(nn.1, test.data[,-1])[,1]
true_neg = sum(test.data[,1]==0 & pred.nn>0.5)
true_pos = sum(test.data[,1]==1 & pred.nn<0.5)
false_pos = sum(test.data[,1]==0 & pred.nn<0.5)
false_neg = sum(test.data[,1]==1 & pred.nn>0.5)
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
auc(nn.1, response = test_data[,1], predictor = pred.nn)
?auc
install.packages("ROCR")
library("ROCR")
?ROCR
roc_(response = test_data[,1], predictor = pred.nn)
roc_(data = nn.1, response = test_data[,1], predictor = pred.nn)
?svm
install.packages("e1071")
library("e1071")
?svm
# install.packages(neuralnet)
library(neuralnet)
library(MASS)
library(caret)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
# training data
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Neural Network
yf = as.factor(train.data[,1])
svm.1 <- svm(yf ~., data = train.data[,-1]) #training neural net
svm.1
pred.svm = predict(svm.1, test.data[,-1])[,1]
predict(svm.1, test.data[,-1])
# install.packages(neuralnet)
library(neuralnet)
library(MASS)
library(caret)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
# training data
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Neural Network
yf = as.factor(train.data[,1])
nn.1 <- neuralnet(yf ~., data = train.data[,-1], hidden = 3) #training neural net
pred.nn = predict(nn.1, test.data[,-1])[,1]
true_neg = sum(test.data[,1]==0 & pred.nn>0.5)
true_pos = sum(test.data[,1]==1 & pred.nn<0.5)
false_pos = sum(test.data[,1]==0 & pred.nn<0.5)
false_neg = sum(test.data[,1]==1 & pred.nn>0.5)
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =", prediction_accuracy))
?nn
?neuralnet
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
prediction_accuracy
true_neg = sum(test.data[,1]==0 & pred.nn>0.5)
true_pos = sum(test.data[,1]==1 & pred.nn<0.5)
false_pos = sum(test.data[,1]==0 & pred.nn<0.5)
false_neg = sum(test.data[,1]==1 & pred.nn>0.5)
true_neg
true_pos
false_pos
false_neg
nn.1 <- neuralnet(yf ~., data = train.data[,-1], hidden = 3) #training neural net
pred.nn = predict(nn.1, test.data[,-1])[,1]
true_neg
true_pos
false_pos
false_neg
# install.packages(neuralnet)
library(neuralnet)
library(MASS)
library(caret)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
# training data
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Neural Network
yf = as.factor(train.data[,1])
svm.1 <- svm(yf ~., data = train.data[,-1]) #training neural net
pred.svm = predict(svm.1, test.data[,-1])
true_neg = sum(test.data[,1]==0 & pred.svm>0.5)
true_pos = sum(test.data[,1]==1 & pred.svm<0.5)
false_pos = sum(test.data[,1]==0 & pred.svm<0.5)
false_neg = sum(test.data[,1]==1 & pred.svm>0.5)
pred.svm
true_neg
true_pos
test.data
# install.packages(neuralnet)
library(neuralnet)
library(MASS)
library(caret)
set.seed(2020)
#seperate train and test
data_familiarity = data$consideration
#sample train_size of the data
idx_train = createDataPartition(data_familiarity, p = train_size, list = F)
train_data = cbind( data_familiarity[idx_train] , data$predictors[idx_train,] )
test_data = cbind( data_familiarity[-idx_train] , data$predictors[-idx_train,] )
# training data
train.1 =  train_data[train_data[,1]==1,] # train data with label 1
train.0 =  train_data[train_data[,1]==0,] # train data with label 0
train.data = data.frame(rbind(train.1,train.0)) # merge them
# testing data from the same data generating process
test.1 =  test_data[test_data[,1]==1,] # test data with label 1
test.0 =  test_data[test_data[,1]==0,] # test data with label 0
test.data = data.frame(rbind(test.1,test.0)) # merge them
# Classification by Neural Network
yf = as.factor(train.data[,1])
svm.1 <- svm(yf ~., data = train.data[,-1]) #training neural net
pred.svm = predict(svm.1, test.data[,-1])
true_neg = sum(test.data[,1]==0 & pred.svm>0.5)
true_pos = sum(test.data[,1]==1 & pred.svm<0.5)
false_pos = sum(test.data[,1]==0 & pred.svm<0.5)
false_neg = sum(test.data[,1]==1 & pred.svm>0.5)
prediction_accuracy = (true_neg + true_pos ) / nrow(test.data)
print(paste("prediction accuracy =", prediction_accuracy))
predict(svm.1, test.data[,-1])
sum(predict(svm.1, test.data[,-1]))
pred.svm = sum(predict(svm.1, test.data[,-1])[1])
# Pathing - fix this on your machine first (set to local Git directory)
path = "~/Documents/Econometrie/Masters/Seminar Nielsen/Seminar"
# Fix seed and load libraries
set.seed(123456)
library(mvtnorm); library(dplyr); library(survey); library(ggplot2); library(robustbase)
setwd(path)
source("./200302_simulation_support_functions.R")
#######################################################################
####### CHOOSE TRUE PARAMETERS FOR TARGET AND NON-TARGET GROUPS #######
#######################################################################
# NOTE: If you want to use target and non-target parameters as ...
#       originally derived from the Nielsen data, set boolean ...
#       use_Nielsen_parameters below to TRUE
true_target_params = c(-1.5, -3, 3.2, -1.0, 0.5, 1.0, .75)
true_nontarget_params = c(-2.0, 0.6, 0.4, 0.2, 0.1, 0.5, 1)
use_Nielsen_parameters = FALSE
CPS <- rbind.data.frame(c(0.203195,0.10298,0.100214),
c(0.185959,0.092719,0.09324),
c(0.186438,0.091954,0.094484),
c(0.424408,0.195766,0.228643))
colnames(CPS) = c("Total", "Male", "Female")
rownames(CPS) = c("25-34", "35-44", "45-54", "55-99")
target_gender = "Male"
target_age = "25-34"
kpi = "Consideration"
# Separate target age group for future reference
target_min_age = as.numeric(substring(target_age, 1, 2))
target_max_age = as.numeric(substring(target_age, nchar(target_age)-1, nchar(target_age)))
# Load Pointlogic source data
source_data = read.csv("./cleaned_unified_sample.csv")
# Separate true data into predictors and responses, and split target and non-target data
true_fullsample_variables = separate_predictors_responses(source_data)
subsamples = split_sample(source_data, tolower(target_gender), target_min_age, target_max_age)
true_target_variables = separate_predictors_responses(subsamples$target)
true_nontarget_variables = separate_predictors_responses(subsamples$nontarget)
# Fit logit coefficients of the true target data
logit.target.familiarity <- glm( true_target_variables$familiarity ~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.awareness <- glm( true_target_variables$awareness ~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.consideration <- glm( true_target_variables$consideration ~ true_target_variables$predictors,
family=binomial(link="logit") )
# Fit logit coefficients of the true non-target data
logit.nontarget.familiarity <- glm( true_nontarget_variables$familiarity ~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.awareness <- glm( true_nontarget_variables$awareness ~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.consideration <- glm( true_nontarget_variables$consideration ~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
# Derive some necessary info from user inputs
necessary_info = initialise_target_group(target_gender, target_age, kpi)
# If user chose to use parameters derived from Nielsen source data, override parameter choices
if (use_Nielsen_parameters == TRUE) {
true_target_params = unname(necessary_info$true_target_params)
true_nontarget_params = unname(necessary_info$true_nontarget_params)
}
# Compute population-level parameters as linear combination of target and non-target params
true_population_params = (CPS[target_age, target_gender]*true_target_params
+ (1-CPS[target_age, target_gender])*true_nontarget_params)
?glmnet
library(mvtnorm); library(dplyr); library(survey); library(ggplot2); library(robustbase); library(glmnet)
install.packages(glmnet)
install.packages("glmnet")
