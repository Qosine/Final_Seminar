w_contam_results
wo_contam_results
w_contam_1_3$BS_estimates
w_contam_1_3$MI_estimates
w_contam_1_3$MI_DDC_estimates
load("D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Topics in Advanced Statistics/Assignment 2/fullrun.RData")
MSE <- function(true_values, estimates) {
MSE = rep(-1, ncol(estimates))
for (variable in 1:ncol(estimates)) {
MSE[variable] = mean( (estimates[,variable]-true_values[variable])^2 )
}
return(MSE)
}
process_output <- function(output, true_betas) {
MI_SD = sqrt(diag(var(output$MI_estimates)))
BS_SD = sqrt(diag(var(output$BS_estimates)))
MI_DDC_SD = sqrt(diag(var(output$MI_DDC_estimates)))
BS_DDC_SD = sqrt(diag(var(output$BS_DDC_estimates)))
out = data.frame("MI" = c(mean(MSE(true_betas, output$MI_estimates)),
mean(MSE(MI_SD, output$MI_std_errors)),
MI_SD),
"MI.DDC" = c(mean(MSE(true_betas, output$MI_DDC_estimates)),
mean(MSE(MI_DDC_SD, output$MI_DDC_errors)),
MI_DDC_SD),
"BS" = c(mean(MSE(true_betas, output$BS_estimates)),
mean(MSE(BS_SD, output$BS_std_errors)),
BS_SD),
"BS.DDC" = c(mean(MSE(true_betas, output$BS_DDC_estimates)),
mean(MSE(BS_DDC_SD, output$BS_DDC_errors)),
BS_DDC_SD))
rownames(out) = c("MSE.beta", "MSE.SE", paste("SD.beta", 1:length(true_betas), sep=""))
return(out)
}
true_beta_1to3 = c(0,1,1); true_beta_4 = c(0,1,1,1,1,1)
scenario1_results = process_output(scenario_1.1, true_beta_1to3)
scenario2_results = process_output(scenario_1.2, true_beta_1to3)
scenario3_results = process_output(scenario_1.3, true_beta_1to3)
scenario4_results = process_output(scenario_2, true_beta_4)
scenario1_results
scenario3_results
scenario4_results
load("D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Topics in Advanced Statistics/Assignment 2/fullrun.RData")
percent_bias <- function(true_values, estimates) {
return( abs((colMeans(estimates[,2:ncol(estimates)])-true_values[2:length(true_values)])/true_values[2:length(true_values)]) )
}
RMSE <- function(true_values, estimates) {
RMSE = rep(-1, ncol(estimates))
for (variable in 1:ncol(estimates)) {
RMSE[variable] = sqrt(mean( (estimates[,variable]-true_values[variable])^2 ))
}
return(RMSE)
}
process_output <- function(output, true_betas) {
MI_SD = sqrt(diag(var(output$MI_estimates)))
BS_SD = sqrt(diag(var(output$BS_estimates)))
MI_DDC_SD = sqrt(diag(var(output$MI_DDC_estimates)))
BS_DDC_SD = sqrt(diag(var(output$BS_DDC_estimates)))
out = data.frame("MI" = c(#percent_bias(true_betas, output$MI_estimates),
mean(RMSE(true_betas, output$MI_estimates)),
mean(RMSE(MI_SD, output$MI_std_errors)),
MI_SD),
"MI.DDC" = c(#percent_bias(true_betas, output$MI_DDC_estimates),
mean(RMSE(true_betas, output$MI_DDC_estimates)),
mean(RMSE(MI_DDC_SD, output$MI_DDC_errors)),
MI_DDC_SD),
"BS" = c(#percent_bias(true_betas, output$BS_estimates),
mean(RMSE(true_betas, output$BS_estimates)),
mean(RMSE(BS_SD, output$BS_std_errors)),
BS_SD),
"BS.DDC" = c(#percent_bias(true_betas, output$BS_DDC_estimates),
mean(RMSE(true_betas, output$BS_DDC_estimates)),
mean(RMSE(BS_DDC_SD, output$BS_DDC_errors)),
BS_DDC_SD))
rownames(out) = c("RMSE.beta", "RMSE.SE", paste("SD.beta", 1:length(true_betas), sep=""))
return(out)
}
true_beta_1to3 = c(0,1,1); true_beta_4 = c(0,1,1,1,1,1)
scenario1_results = process_output(scenario_1.1, true_beta_1to3)
scenario2_results = process_output(scenario_1.2, true_beta_1to3)
scenario3_results_corr = process_output(scenario_1.3, true_beta_1to3)
scenario3_results_no_corr = process_output(scenario_1.3_no_correction, true_beta_1to3)
scenario4_results = process_output(scenario_2, true_beta_4)
results = c("scenario1_results", "scenario2_results", "scenario3_results_corr",
"scenario3_results_no_corr", "scenario4_results")
for (i in results) {
print(i)
print(round((get(i)*100),2))
}
percent_bias <- function(true_values, estimates) {
return( abs((colMeans(estimates[,2:ncol(estimates)])-true_values[2:length(true_values)])/true_values[2:length(true_values)]) )
}
MSE <- function(true_values, estimates) {
MSE = rep(-1, ncol(estimates))
for (variable in 1:ncol(estimates)) {
MSE[variable] = mean( (estimates[,variable]-true_values[variable])^2 )
}
return(MSE)
}
process_output <- function(output, true_betas) {
MI_SD = sqrt(diag(var(output$MI_estimates)))
BS_SD = sqrt(diag(var(output$BS_estimates)))
MI_DDC_SD = sqrt(diag(var(output$MI_DDC_estimates)))
BS_DDC_SD = sqrt(diag(var(output$BS_DDC_estimates)))
out = data.frame("MI" = c(#percent_bias(true_betas, output$MI_estimates),
mean(MSE(true_betas, output$MI_estimates)),
mean(MSE(MI_SD, output$MI_std_errors)),
MI_SD),
"MI.DDC" = c(#percent_bias(true_betas, output$MI_DDC_estimates),
mean(MSE(true_betas, output$MI_DDC_estimates)),
mean(MSE(MI_DDC_SD, output$MI_DDC_errors)),
MI_DDC_SD),
"BS" = c(#percent_bias(true_betas, output$BS_estimates),
mean(MSE(true_betas, output$BS_estimates)),
mean(MSE(BS_SD, output$BS_std_errors)),
BS_SD),
"BS.DDC" = c(#percent_bias(true_betas, output$BS_DDC_estimates),
mean(MSE(true_betas, output$BS_DDC_estimates)),
mean(MSE(BS_DDC_SD, output$BS_DDC_errors)),
BS_DDC_SD))
rownames(out) = c("MSE.beta", "MSE.SE", paste("SD.beta", 1:length(true_betas), sep=""))
return(out)
}
scenario1_results = process_output(scenario_1.1, true_beta_1to3)
scenario2_results = process_output(scenario_1.2, true_beta_1to3)
scenario3_results_corr = process_output(scenario_1.3, true_beta_1to3)
scenario3_results_no_corr = process_output(scenario_1.3_no_correction, true_beta_1to3)
scenario4_results = process_output(scenario_2, true_beta_4)
results = c("scenario1_results", "scenario2_results", "scenario3_results_corr",
"scenario3_results_no_corr", "scenario4_results")
for (i in results) {
print(i)
print(round((get(i)*100),2))
}
load("D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Topics in Advanced Statistics/Assignment 2/missing_and_contamination.RData")
percent_bias <- function(true_values, estimates) {
return( abs((colMeans(estimates[,2:ncol(estimates)])-true_values[2:length(true_values)])/true_values[2:length(true_values)]) )
}
MSE <- function(true_values, estimates) {
MSE = rep(-1, ncol(estimates))
for (variable in 1:ncol(estimates)) {
MSE[variable] = mean( (estimates[,variable]-true_values[variable])^2 )
}
return(MSE)
}
process_output <- function(output, true_betas) {
MI_SD = sqrt(diag(var(output$MI_estimates)))
BS_SD = sqrt(diag(var(output$BS_estimates)))
MI_DDC_SD = sqrt(diag(var(output$MI_DDC_estimates)))
BS_DDC_SD = sqrt(diag(var(output$BS_DDC_estimates)))
out = data.frame("MI" = c(#percent_bias(true_betas, output$MI_estimates),
mean(MSE(true_betas, output$MI_estimates)),
mean(MSE(MI_SD, output$MI_std_errors)),
MI_SD),
"MI.DDC" = c(#percent_bias(true_betas, output$MI_DDC_estimates),
mean(MSE(true_betas, output$MI_DDC_estimates)),
mean(MSE(MI_DDC_SD, output$MI_DDC_errors)),
MI_DDC_SD),
"BS" = c(#percent_bias(true_betas, output$BS_estimates),
mean(MSE(true_betas, output$BS_estimates)),
mean(MSE(BS_SD, output$BS_std_errors)),
BS_SD),
"BS.DDC" = c(#percent_bias(true_betas, output$BS_DDC_estimates),
mean(MSE(true_betas, output$BS_DDC_estimates)),
mean(MSE(BS_DDC_SD, output$BS_DDC_errors)),
BS_DDC_SD))
rownames(out) = c("MSE.beta", "MSE.SE", paste("SD.beta", 1:length(true_betas), sep=""))
return(out)
}
scenario1_contam = process_output(scenario_1.1_contam, true_beta_1to3)
scenario2_contam = process_output(scenario_1.2_contam, true_beta_1to3)
scenario3_contam = process_output(scenario_1.3_contam, true_beta_1to3)
true_beta_1to3 = c(0,1,1); true_beta_4 = c(0,1,1,1,1,1)
scenario1_contam = process_output(scenario_1.1_contam, true_beta_1to3)
scenario2_contam = process_output(scenario_1.2_contam, true_beta_1to3)
scenario3_contam = process_output(scenario_1.3_contam, true_beta_1to3)
results = c("scenario1_contam", "scenario2_contam", "scenario3_contam")
for (i in results) {
print(i)
print(round((get(i)*100),2))
}
# Pathing - fix this on your machine first (set to local Git directory)
# path = "~/Documents/Econometrie/Masters/Seminar Nielsen"
path = "D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Seminar Case Studies/Git/Seminar"
setwd(path)
# Fix seed and load libraries
set.seed(200127)
library(mvtnorm)
library(simcausal)
library(dplyr)
library(survey)
library(ggplot2)
library(robustbase)
# Load Pointlogic source data
source_data = read.csv("./cleaned_unified_sample.csv")
# Separate true data into predictors and responses, and split target and non-target data
true_fullsample_variables = separate_predictors_responses(source_data)
subsamples = split_sample(source_data)
true_target_variables = separate_predictors_responses(subsamples$target)
true_nontarget_variables = separate_predictors_responses(subsamples$nontarget)
# Fit logit coefficients of the true target data
logit.target.familiarity <- glm( true_target_variables$familiarity
~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.awareness <- glm( true_target_variables$awareness
~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.consideration <- glm( true_target_variables$consideration
~ true_target_variables$predictors,
family=binomial(link="logit") )
# Fit logit coefficients of the true non-target data
logit.nontarget.familiarity <- glm( true_nontarget_variables$familiarity
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.awareness <- glm( true_nontarget_variables$awareness
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.consideration <- glm( true_nontarget_variables$consideration
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
# CPS weights
CPS <- rbind.data.frame(c(0.203195,0.10298,0.100214),
c(0.185959,0.092719,0.09324),
c(0.186438,0.091954,0.094484),
c(0.424408,0.195766,0.228643))
colnames(CPS) = c("Total", "Male", "Female")
rownames(CPS) = c("25-34", "35-44", "45-54", "55-99")
source("./200302_simulation_support_functions.R")
# Pathing - fix this on your machine first (set to local Git directory)
# path = "~/Documents/Econometrie/Masters/Seminar Nielsen"
path = "D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Seminar Case Studies/Git/Seminar"
setwd(path)
source("./200302_simulation_support_functions.R")
# Fix seed and load libraries
set.seed(200127)
library(mvtnorm)
library(simcausal)
library(dplyr)
library(survey)
library(ggplot2)
library(robustbase)
# Load Pointlogic source data
source_data = read.csv("./cleaned_unified_sample.csv")
# Separate true data into predictors and responses, and split target and non-target data
true_fullsample_variables = separate_predictors_responses(source_data)
subsamples = split_sample(source_data)
true_target_variables = separate_predictors_responses(subsamples$target)
true_nontarget_variables = separate_predictors_responses(subsamples$nontarget)
# Fit logit coefficients of the true target data
logit.target.familiarity <- glm( true_target_variables$familiarity
~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.awareness <- glm( true_target_variables$awareness
~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.consideration <- glm( true_target_variables$consideration
~ true_target_variables$predictors,
family=binomial(link="logit") )
# Fit logit coefficients of the true non-target data
logit.nontarget.familiarity <- glm( true_nontarget_variables$familiarity
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.awareness <- glm( true_nontarget_variables$awareness
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.consideration <- glm( true_nontarget_variables$consideration
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
# CPS weights
CPS <- rbind.data.frame(c(0.203195,0.10298,0.100214),
c(0.185959,0.092719,0.09324),
c(0.186438,0.091954,0.094484),
c(0.424408,0.195766,0.228643))
colnames(CPS) = c("Total", "Male", "Female")
rownames(CPS) = c("25-34", "35-44", "45-54", "55-99")
tolower("HI")
target_age = "25-34"
substring(target_age, 1, 2)
substring(target_age, nchar(target_age)-2+1, nchar(target_age))
# Fix seed and load libraries
set.seed(200127)
library(mvtnorm); library(simcausal); library(dplyr); library(survey); library(ggplot2); library(robustbase)
# Pathing - fix this on your machine first (set to local Git directory)
path = "~/Documents/Econometrie/Masters/Seminar Nielsen"
path = "D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Seminar Case Studies/Git/Seminar"
setwd(path)
source("./200302_simulation_support_functions.R")
# CPS weights
CPS <- rbind.data.frame(c(0.203195,0.10298,0.100214),
c(0.185959,0.092719,0.09324),
c(0.186438,0.091954,0.094484),
c(0.424408,0.195766,0.228643))
colnames(CPS) = c("Total", "Male", "Female")
rownames(CPS) = c("25-34", "35-44", "45-54", "55-99")
#######################################################################
################## CHOOSE TARGET GROUP AND KPI BELOW ##################
target_gender = "Male" # options are "Male", "Female"
target_age = "25-34" # options are "25-34", "35-44", "45-54", "55-99"
kpi = "Consideration" # options are "Familiarity", "Consideration", "Awareness"
################## CHOOSE TARGET GROUP AND KPI ABOVE ##################
#######################################################################
target_min_age = substring(target_age, 1, 2)
target_max_age = substring(target_age, nchar(target_age)-1, nchar(target_age))
# Load Pointlogic source data
source_data = read.csv("./cleaned_unified_sample.csv")
# Separate true data into predictors and responses, and split target and non-target data
true_fullsample_variables = separate_predictors_responses(source_data)
subsamples = split_sample(source_data, target_gender, target_min_age, target_max_age)
true_target_variables = separate_predictors_responses(subsamples$target)
true_nontarget_variables = separate_predictors_responses(subsamples$nontarget)
# Fit logit coefficients of the true target data
logit.target.familiarity <- glm( true_target_variables$familiarity
~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.awareness <- glm( true_target_variables$awareness
~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.consideration <- glm( true_target_variables$consideration
~ true_target_variables$predictors,
family=binomial(link="logit") )
# Fit logit coefficients of the true non-target data
logit.nontarget.familiarity <- glm( true_nontarget_variables$familiarity
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.awareness <- glm( true_nontarget_variables$awareness
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.consideration <- glm( true_nontarget_variables$consideration
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
# Derive some necessary info from user inputs
necessary_info = initialise_target_group(target_gender, target_age)
true_population_params = necessary_info$true_population_params
simulated_target_predictors = necessary_info$target_data
simulated_population = list()
simulated_population$predictors = add_constant(simulated_target_predictors)
simulated_population$familiarity = generate_response(simulated_population$predictors,
logit.target.familiarity$coefficients,
nrow(simulated_population$predictors) )
simulated_population$awareness = generate_response(simulated_population$predictors,
logit.target.awareness$coefficients,
nrow(simulated_population$predictors) )
simulated_population$consideration = generate_response(simulated_population$predictors,
logit.target.consideration$coefficients,
nrow(simulated_population$predictors) )
# Fit logit coefficients of the true target data
logit.target.familiarity <- glm( true_target_variables$familiarity ~ true_target_variables$predictors,
family=binomial(link="logit") )
true_target_variables$familiarity
source_data
target_min_age = as.numeric(substring(target_age, 1, 2))
target_max_age
target_min_age
target_max_age = as.numeric(substring(target_age, nchar(target_age)-1, nchar(target_age)))
subsamples = split_sample(source_data, target_gender, target_min_age, target_max_age)
true_target_variables = separate_predictors_responses(subsamples$target)
true_nontarget_variables = separate_predictors_responses(subsamples$nontarget)
# Fit logit coefficients of the true target data
logit.target.familiarity <- glm( true_target_variables$familiarity ~ true_target_variables$predictors,
family=binomial(link="logit") )
true_target_variables$familiarity
target_max_age
subsamples = split_sample(source_data, tolower(target_gender), target_min_age, target_max_age)
true_target_variables = separate_predictors_responses(subsamples$target)
true_target_variables
# Fit logit coefficients of the true target data
logit.target.familiarity <- glm( true_target_variables$familiarity ~ true_target_variables$predictors,
family=binomial(link="logit") )
# Fix seed and load libraries
set.seed(200127)
library(mvtnorm); library(simcausal); library(dplyr); library(survey); library(ggplot2); library(robustbase)
# Pathing - fix this on your machine first (set to local Git directory)
path = "~/Documents/Econometrie/Masters/Seminar Nielsen"
path = "D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Seminar Case Studies/Git/Seminar"
setwd(path)
source("./200302_simulation_support_functions.R")
# CPS weights
CPS <- rbind.data.frame(c(0.203195,0.10298,0.100214),
c(0.185959,0.092719,0.09324),
c(0.186438,0.091954,0.094484),
c(0.424408,0.195766,0.228643))
colnames(CPS) = c("Total", "Male", "Female")
rownames(CPS) = c("25-34", "35-44", "45-54", "55-99")
#######################################################################
################## CHOOSE TARGET GROUP AND KPI BELOW ##################
target_gender = "Male" # options are "Male", "Female"
target_age = "25-34" # options are "25-34", "35-44", "45-54", "55-99"
kpi = "Consideration" # options are "Familiarity", "Consideration", "Awareness"
################## CHOOSE TARGET GROUP AND KPI ABOVE ##################
#######################################################################
target_min_age = as.numeric(substring(target_age, 1, 2))
target_max_age = as.numeric(substring(target_age, nchar(target_age)-1, nchar(target_age)))
# Load Pointlogic source data
source_data = read.csv("./cleaned_unified_sample.csv")
# Separate true data into predictors and responses, and split target and non-target data
true_fullsample_variables = separate_predictors_responses(source_data)
subsamples = split_sample(source_data, tolower(target_gender), target_min_age, target_max_age)
true_target_variables = separate_predictors_responses(subsamples$target)
true_nontarget_variables = separate_predictors_responses(subsamples$nontarget)
# Fit logit coefficients of the true target data
logit.target.familiarity <- glm( true_target_variables$familiarity ~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.awareness <- glm( true_target_variables$awareness ~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.consideration <- glm( true_target_variables$consideration ~ true_target_variables$predictors,
family=binomial(link="logit") )
# Fit logit coefficients of the true non-target data
logit.nontarget.familiarity <- glm( true_nontarget_variables$familiarity
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.awareness <- glm( true_nontarget_variables$awareness
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.consideration <- glm( true_nontarget_variables$consideration
~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
# Derive some necessary info from user inputs
necessary_info = initialise_target_group(target_gender, target_age)
true_population_params = necessary_info$true_population_params
simulated_target_predictors = necessary_info$target_data
simulated_population = list()
simulated_population$predictors = add_constant(simulated_target_predictors)
simulated_population$familiarity = generate_response(simulated_population$predictors,
logit.target.familiarity$coefficients,
nrow(simulated_population$predictors) )
simulated_population$awareness = generate_response(simulated_population$predictors,
logit.target.awareness$coefficients,
nrow(simulated_population$predictors) )
simulated_population$consideration = generate_response(simulated_population$predictors,
logit.target.consideration$coefficients,
nrow(simulated_population$predictors) )
# Allocate memory for simulation results
target_glm_results = data.frame(matrix(0, reps, ncol(add_constant(true_fullsample_variables$predictors))))
total_svyglm_results = data.frame(matrix(0, reps, ncol(add_constant(true_fullsample_variables$predictors))))
N = 2500
Q = .80
reps = 100
target_glm_results = data.frame(matrix(0, reps, ncol(add_constant(true_fullsample_variables$predictors))))
total_svyglm_results = data.frame(matrix(0, reps, ncol(add_constant(true_fullsample_variables$predictors))))
interaction_results = data.frame(matrix(0, reps, ncol(add_constant(true_fullsample_variables$predictors))*2))
# Name columns of results df
coefficient_names = c("Intercept", "Audio", "Digital", "Program", "TV",
"VOD", "Youtube", "Target", "Target*Audio", "Target*Digital",
"Target*Program", "Target*TV", "Target*VOD", "Target*Youtube")
colnames(target_audience_glm) = coefficient_names[1:(length(coefficient_names)/2)]
colnames(total_audience_svyglm) = coefficient_names[1:(length(coefficient_names)/2)]
colnames(interaction_glm) = coefficient_names
colnames(target_glm_results) = coefficient_names[1:(length(coefficient_names)/2)]
colnames(total_svyglm_results) = coefficient_names[1:(length(coefficient_names)/2)]
colnames(interaction_results) = coefficient_names
# Create index of random samples for target and non-target data
idx_rs_targets = sample( 1:nrow(simulated_population$predictors), N*Q )
idx_rs_nontargets = sample( 1:nrow(subsamples$nontarget), (N*(1-Q)) )
# Compile explanatory variables
rs_targets = rs_nontargets = list()
rs_targets$predictors = simulated_population$predictors[idx_rs_targets,]
nontarget_data = separate_predictors_responses(subsamples$nontarget[idx_rs_nontargets,])
rs_nontargets$predictors = add_constant(nontarget_data$predictors)
# Compile dependent variable (KPI)
if (tolower(kpi) == "consideration") {
rs_targets$kpi = simulated_population$consideration[idx_rs_targets]
rs_nontargets$kpi = nontarget_data$consideration
} else if (tolower(kpi) == "awareness") {
rs_targets$kpi = simulated_population$awareness[idx_rs_targets]
rs_nontargets$kpi = nontarget_data$awareness
} else if (tolower(kpi) == "familiarity") {
rs_targets$kpi = simulated_population$familiarity[idx_rs_targets]
rs_nontargets$kpi = nontarget_data$familiarity
} else {
print("Invalid KPI specified, breaking the loop")
break
}
# Combine the target and non-target data into a single matrix
full_sample = list()
full_sample$predictors = rbind(rs_targets$predictors,
rs_nontargets$predictors)
full_sample$kpi = append(rs_targets$kpi,
rs_nontargets$kpi)
# Compute weights
weights = compute_weights(Q,
CPS[target_age, target_gender],
nrow(rs_targets$predictors),
nrow(rs_nontargets$predictors))
# Create data for interaction model (dependent is same as full_sample)
full_sample_w_interact = list()
interaction = rbind(rs_targets$predictors,
matrix(0,
nrow(rs_nontargets$predictors),
ncol(rs_nontargets$predictors)))
colnames(interaction) = rename_interaction_columns(colnames(interaction))
full_sample_w_interact$predictors = cbind(full_sample$predictors, interaction)
# Fit regular logit for model without interactions
glm.target_audience <- glm(rs_targets$kpi ~ 0 + rs_targets$predictors,
family = binomial(link="logit"))
# Fit weighted logit for model without interactions
svy_inputs = create_svyglm_inputs(full_sample$predictors, full_sample$kpi)
design_func <- svydesign(id = ~1,
data = svy_inputs$data,
weight = weights)
svyglm.total_audience <- svyglm(formula = svy_inputs$func,
design =  design_func,
family = "quasibinomial")
# Fit unweighted logit for model with interactions
glm.interaction_model <-  glm(full_sample$kpi ~ 0 + full_sample_w_interact$predictors,
family = binomial(link="logit"))
# Store results of current run
target_glm_results[1,] = glm.target_audience$coefficients
total_svyglm_results[1,] = svyglm.total_audience$coefficients
interaction_results[1,] = glm.interaction_model$coefficients
li_results = list()
li_results$glm_target_audience <- target_glm_results
li_results$svyglm_total_audience <- total_svyglm_results
li_results$glm_interaction_model <- interaction_results[,1:7] + interaction_results[,8:14]
