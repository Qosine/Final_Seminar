rownames(out) = c("MSE.beta", "MSE.SE", paste("SD.beta", 1:length(true_betas), sep=""))
return(out)
}
true_beta_1to3 = c(0,1,1); true_beta_4 = c(0,1,1,1,1,1)
scenario1_results = process_output(scenario_1.1, true_beta_1to3)
scenario2_results = process_output(scenario_1.2, true_beta_1to3)
scenario3_results = process_output(scenario_1.3, true_beta_1to3)
scenario4_results = process_output(scenario_2, true_beta_4)
scenario1_results
scenario3_results
scenario4_results
load("D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Topics in Advanced Statistics/Assignment 2/fullrun.RData")
percent_bias <- function(true_values, estimates) {
return( abs((colMeans(estimates[,2:ncol(estimates)])-true_values[2:length(true_values)])/true_values[2:length(true_values)]) )
}
RMSE <- function(true_values, estimates) {
RMSE = rep(-1, ncol(estimates))
for (variable in 1:ncol(estimates)) {
RMSE[variable] = sqrt(mean( (estimates[,variable]-true_values[variable])^2 ))
}
return(RMSE)
}
process_output <- function(output, true_betas) {
MI_SD = sqrt(diag(var(output$MI_estimates)))
BS_SD = sqrt(diag(var(output$BS_estimates)))
MI_DDC_SD = sqrt(diag(var(output$MI_DDC_estimates)))
BS_DDC_SD = sqrt(diag(var(output$BS_DDC_estimates)))
out = data.frame("MI" = c(#percent_bias(true_betas, output$MI_estimates),
mean(RMSE(true_betas, output$MI_estimates)),
mean(RMSE(MI_SD, output$MI_std_errors)),
MI_SD),
"MI.DDC" = c(#percent_bias(true_betas, output$MI_DDC_estimates),
mean(RMSE(true_betas, output$MI_DDC_estimates)),
mean(RMSE(MI_DDC_SD, output$MI_DDC_errors)),
MI_DDC_SD),
"BS" = c(#percent_bias(true_betas, output$BS_estimates),
mean(RMSE(true_betas, output$BS_estimates)),
mean(RMSE(BS_SD, output$BS_std_errors)),
BS_SD),
"BS.DDC" = c(#percent_bias(true_betas, output$BS_DDC_estimates),
mean(RMSE(true_betas, output$BS_DDC_estimates)),
mean(RMSE(BS_DDC_SD, output$BS_DDC_errors)),
BS_DDC_SD))
rownames(out) = c("RMSE.beta", "RMSE.SE", paste("SD.beta", 1:length(true_betas), sep=""))
return(out)
}
true_beta_1to3 = c(0,1,1); true_beta_4 = c(0,1,1,1,1,1)
scenario1_results = process_output(scenario_1.1, true_beta_1to3)
scenario2_results = process_output(scenario_1.2, true_beta_1to3)
scenario3_results_corr = process_output(scenario_1.3, true_beta_1to3)
scenario3_results_no_corr = process_output(scenario_1.3_no_correction, true_beta_1to3)
scenario4_results = process_output(scenario_2, true_beta_4)
results = c("scenario1_results", "scenario2_results", "scenario3_results_corr",
"scenario3_results_no_corr", "scenario4_results")
for (i in results) {
print(i)
print(round((get(i)*100),2))
}
percent_bias <- function(true_values, estimates) {
return( abs((colMeans(estimates[,2:ncol(estimates)])-true_values[2:length(true_values)])/true_values[2:length(true_values)]) )
}
MSE <- function(true_values, estimates) {
MSE = rep(-1, ncol(estimates))
for (variable in 1:ncol(estimates)) {
MSE[variable] = mean( (estimates[,variable]-true_values[variable])^2 )
}
return(MSE)
}
process_output <- function(output, true_betas) {
MI_SD = sqrt(diag(var(output$MI_estimates)))
BS_SD = sqrt(diag(var(output$BS_estimates)))
MI_DDC_SD = sqrt(diag(var(output$MI_DDC_estimates)))
BS_DDC_SD = sqrt(diag(var(output$BS_DDC_estimates)))
out = data.frame("MI" = c(#percent_bias(true_betas, output$MI_estimates),
mean(MSE(true_betas, output$MI_estimates)),
mean(MSE(MI_SD, output$MI_std_errors)),
MI_SD),
"MI.DDC" = c(#percent_bias(true_betas, output$MI_DDC_estimates),
mean(MSE(true_betas, output$MI_DDC_estimates)),
mean(MSE(MI_DDC_SD, output$MI_DDC_errors)),
MI_DDC_SD),
"BS" = c(#percent_bias(true_betas, output$BS_estimates),
mean(MSE(true_betas, output$BS_estimates)),
mean(MSE(BS_SD, output$BS_std_errors)),
BS_SD),
"BS.DDC" = c(#percent_bias(true_betas, output$BS_DDC_estimates),
mean(MSE(true_betas, output$BS_DDC_estimates)),
mean(MSE(BS_DDC_SD, output$BS_DDC_errors)),
BS_DDC_SD))
rownames(out) = c("MSE.beta", "MSE.SE", paste("SD.beta", 1:length(true_betas), sep=""))
return(out)
}
scenario1_results = process_output(scenario_1.1, true_beta_1to3)
scenario2_results = process_output(scenario_1.2, true_beta_1to3)
scenario3_results_corr = process_output(scenario_1.3, true_beta_1to3)
scenario3_results_no_corr = process_output(scenario_1.3_no_correction, true_beta_1to3)
scenario4_results = process_output(scenario_2, true_beta_4)
results = c("scenario1_results", "scenario2_results", "scenario3_results_corr",
"scenario3_results_no_corr", "scenario4_results")
for (i in results) {
print(i)
print(round((get(i)*100),2))
}
load("D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Topics in Advanced Statistics/Assignment 2/missing_and_contamination.RData")
percent_bias <- function(true_values, estimates) {
return( abs((colMeans(estimates[,2:ncol(estimates)])-true_values[2:length(true_values)])/true_values[2:length(true_values)]) )
}
MSE <- function(true_values, estimates) {
MSE = rep(-1, ncol(estimates))
for (variable in 1:ncol(estimates)) {
MSE[variable] = mean( (estimates[,variable]-true_values[variable])^2 )
}
return(MSE)
}
process_output <- function(output, true_betas) {
MI_SD = sqrt(diag(var(output$MI_estimates)))
BS_SD = sqrt(diag(var(output$BS_estimates)))
MI_DDC_SD = sqrt(diag(var(output$MI_DDC_estimates)))
BS_DDC_SD = sqrt(diag(var(output$BS_DDC_estimates)))
out = data.frame("MI" = c(#percent_bias(true_betas, output$MI_estimates),
mean(MSE(true_betas, output$MI_estimates)),
mean(MSE(MI_SD, output$MI_std_errors)),
MI_SD),
"MI.DDC" = c(#percent_bias(true_betas, output$MI_DDC_estimates),
mean(MSE(true_betas, output$MI_DDC_estimates)),
mean(MSE(MI_DDC_SD, output$MI_DDC_errors)),
MI_DDC_SD),
"BS" = c(#percent_bias(true_betas, output$BS_estimates),
mean(MSE(true_betas, output$BS_estimates)),
mean(MSE(BS_SD, output$BS_std_errors)),
BS_SD),
"BS.DDC" = c(#percent_bias(true_betas, output$BS_DDC_estimates),
mean(MSE(true_betas, output$BS_DDC_estimates)),
mean(MSE(BS_DDC_SD, output$BS_DDC_errors)),
BS_DDC_SD))
rownames(out) = c("MSE.beta", "MSE.SE", paste("SD.beta", 1:length(true_betas), sep=""))
return(out)
}
scenario1_contam = process_output(scenario_1.1_contam, true_beta_1to3)
scenario2_contam = process_output(scenario_1.2_contam, true_beta_1to3)
scenario3_contam = process_output(scenario_1.3_contam, true_beta_1to3)
true_beta_1to3 = c(0,1,1); true_beta_4 = c(0,1,1,1,1,1)
scenario1_contam = process_output(scenario_1.1_contam, true_beta_1to3)
scenario2_contam = process_output(scenario_1.2_contam, true_beta_1to3)
scenario3_contam = process_output(scenario_1.3_contam, true_beta_1to3)
results = c("scenario1_contam", "scenario2_contam", "scenario3_contam")
for (i in results) {
print(i)
print(round((get(i)*100),2))
}
0^0
load("D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Seminar Case Studies/Git/Seminar/200302_simulation_results/N7500_R1000.RData")
source('D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Seminar Case Studies/Git/Seminar/200302_simulation_script.R', echo=TRUE)
# Fix seed and load libraries
set.seed(200127)
library(mvtnorm); library(simcausal); library(dplyr); library(survey); library(ggplot2); library(robustbase)
# Pathing - fix this on your machine first (set to local Git directory)
path = "~/Documents/Econometrie/Masters/Seminar Nielsen"
path = "D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Seminar Case Studies/Git/Seminar"
setwd(path)
source("./200302_simulation_support_functions.R")
# CPS weights
CPS <- rbind.data.frame(c(0.203195,0.10298,0.100214),
c(0.185959,0.092719,0.09324),
c(0.186438,0.091954,0.094484),
c(0.424408,0.195766,0.228643))
colnames(CPS) = c("Total", "Male", "Female")
rownames(CPS) = c("25-34", "35-44", "45-54", "55-99")
#######################################################################
################## CHOOSE TARGET GROUP AND KPI BELOW ##################
target_gender = "Male" # options are "Male", "Female"
target_age = "25-34" # options are "25-34", "35-44", "45-54", "55-99"
kpi = "Consideration" # options are "Familiarity", "Consideration", "Awareness"
################## CHOOSE TARGET GROUP AND KPI ABOVE ##################
#######################################################################
target_min_age = as.numeric(substring(target_age, 1, 2))
target_max_age = as.numeric(substring(target_age, nchar(target_age)-1, nchar(target_age)))
# Load Pointlogic source data
source_data = read.csv("./cleaned_unified_sample.csv")
# Separate true data into predictors and responses, and split target and non-target data
true_fullsample_variables = separate_predictors_responses(source_data)
subsamples = split_sample(source_data, tolower(target_gender), target_min_age, target_max_age)
true_target_variables = separate_predictors_responses(subsamples$target)
true_nontarget_variables = separate_predictors_responses(subsamples$nontarget)
# Fit logit coefficients of the true target data
logit.target.familiarity <- glm( true_target_variables$familiarity ~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.awareness <- glm( true_target_variables$awareness ~ true_target_variables$predictors,
family=binomial(link="logit") )
logit.target.consideration <- glm( true_target_variables$consideration ~ true_target_variables$predictors,
family=binomial(link="logit") )
# Fit logit coefficients of the true non-target data
logit.nontarget.familiarity <- glm( true_nontarget_variables$familiarity ~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.awareness <- glm( true_nontarget_variables$awareness ~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
logit.nontarget.consideration <- glm( true_nontarget_variables$consideration ~ true_nontarget_variables$predictors,
family=binomial(link="logit") )
# Derive some necessary info from user inputs
necessary_info = initialise_target_group(target_gender, target_age, kpi)
# KEY STEP: Define target and nontarget parameters
true_target_params = c(-1.5, -3, 3.2, -1.0, 0.5, 1.0, .75)
#true_target_params = unname(logit.target.consideration$coefficients)
true_nontarget_params = c(-2.0, 0.6, 0.4, 0.2, 0.1, 0.5, 1)
#true_nontarget_params = unname(logit.nontarget.consideration$coefficients)
true_population_params = (CPS[target_age, target_gender]*true_target_params
+ (1-CPS[target_age, target_gender])*true_nontarget_params)
# true_target_params = necessary_info$true_target_params
# true_target_params = unname(logit.target.consideration$coefficients)
#true_nontarget_params = unname(logit.nontarget.consideration$coefficients)
# true_population_params = necessary_info$true_population_params
simulated_target_predictors = necessary_info$target_data
simulated_targets = simulated_nontargets = real_nontargets = list()
simulated_targets$predictors = add_constant(simulated_target_predictors)
simulated_targets$kpi = generate_response(simulated_targets$predictors,
true_target_params,
nrow(simulated_targets$predictors) )
load("./simulated_nontarget_predictors.RData")
simulated_nontargets$predictors = add_constant(simulated_nontarget_population)
simulated_nontargets$kpi = generate_response(simulated_nontargets$predictors,
true_nontarget_params,
nrow(simulated_nontargets$predictors))
# real_nontargets$predictors = add_constant(separate_predictors_responses(subsamples$nontarget)$predictors)
# real_nontargets$kpi = generate_response(real_nontargets$predictors, true_nontarget_params, nrow(real_nontargets$predictors))
if ( max(mean(simulated_targets$kpi), mean(simulated_nontargets$kpi)) > 0.9 |
min(mean(simulated_targets$kpi), mean(simulated_nontargets$kpi)) < 0.1 ) {
stop(cat("Parameter choice creates a rare event scenario:\n",
100*round(mean(simulated_targets$kpi),3), "% of targets and ",
100*round(mean(simulated_nontargets$kpi),3), "% of nontargets have a KPI equal to 1\n",
"Breaking program, please try a less extreme parameter set", sep="")) }
N = 7500; Q = 0.1; reps = 100
p = ncol(true_fullsample_variables$predictors) + 1 # add dimension for intercept
target_glm_results = data.frame(matrix(0, reps, p))
nontarget_glm_results = data.frame(matrix(0, reps, p))
total_svyglm_results = data.frame(matrix(0, reps, p))
interaction_results = data.frame(matrix(0, reps, p*2))
var_check_glm = rep(0, reps)
var_check_svyglm = rep(0, reps)
var_check_interaction = rep(0, reps)
# Name columns of results df
coefficient_names = c("Intercept", "Audio", "Digital", "Program", "TV",
"VOD", "Youtube", "Target", "Target*Audio", "Target*Digital",
"Target*Program", "Target*TV", "Target*VOD", "Target*Youtube")
colnames(target_glm_results) = coefficient_names[1:(length(coefficient_names)/2)]
colnames(total_svyglm_results) = coefficient_names[1:(length(coefficient_names)/2)]
colnames(interaction_results) = coefficient_names
# Create index of random samples for target and non-target data
idx_rs_targets = sample( 1:nrow(simulated_targets$predictors), N*Q )
idx_rs_nontargets = sample( 1:nrow(subsamples$nontarget), (N*(1-Q)) )
# Compile explanatory variables
rs_targets = rs_nontargets = list()
rs_targets$predictors = simulated_targets$predictors[idx_rs_targets,]
rs_targets$kpi = simulated_targets$kpi[idx_rs_targets]
rs_nontargets$predictors = simulated_nontargets$predictors[idx_rs_nontargets,]
rs_nontargets$kpi = simulated_nontargets$kpi[idx_rs_nontargets]
# Combine the target and non-target data into a single matrix
full_sample = list()
full_sample$predictors = rbind(rs_targets$predictors,
rs_nontargets$predictors)
full_sample$kpi = append(rs_targets$kpi,
rs_nontargets$kpi)
# Compute weights
weights = compute_weights(Q,
CPS[target_group_age, target_group_gender],
nrow(rs_targets$predictors),
nrow(rs_nontargets$predictors))
# Create data for interaction model (dependent is same as full_sample)
full_sample_w_interact = list()
# If testing within run_simulation(), uncomment the below
target_group_gender = target_gender; target_group_age = target_age
rs_nontargets$kpi = simulated_nontargets$kpi[idx_rs_nontargets]
# Combine the target and non-target data into a single matrix
full_sample = list()
full_sample$predictors = rbind(rs_targets$predictors,
rs_nontargets$predictors)
full_sample$kpi = append(rs_targets$kpi,
rs_nontargets$kpi)
# Compute weights
weights = compute_weights(Q,
CPS[target_group_age, target_group_gender],
nrow(rs_targets$predictors),
nrow(rs_nontargets$predictors))
# Create data for interaction model (dependent is same as full_sample)
full_sample_w_interact = list()
interaction = rbind(rs_targets$predictors,
matrix(0,
nrow(rs_nontargets$predictors),
ncol(rs_nontargets$predictors)))
colnames(interaction) = rename_interaction_columns(colnames(interaction))
full_sample_w_interact$predictors = cbind(full_sample$predictors, interaction)
# Fit regular logit for model without interactions
glm.target_audience <- glm(rs_targets$kpi ~ 0 + rs_targets$predictors,
family = binomial(link="logit"))
glm.nontarget_audience <- glm(rs_nontargets$kpi ~ 0 + rs_nontargets$predictors,
family = binomial(link="logit"))
# Fit weighted logit for model without interactions
svy_inputs = create_svyglm_inputs(full_sample$predictors, full_sample$kpi)
design_func <- svydesign(id = ~1,
data = svy_inputs$data,
weight = weights)
svyglm.total_audience <- svyglm(formula = svy_inputs$func,
design =  design_func,
family = "quasibinomial")
glm.target_audience$coefficients
summary(glm.target_audience)$coefficients
summary(glm.target_audience)$variance
vcov(glm.target_audience)
unname(vcov(glm.target_audience))
glm.true_target_parameters <- glm(rs_targets$kpi ~ 0 + offset(rs_targets$predictors%*%true_target_params),
family = binomial(link = "logit"))
summary(glm.true_target_parameters)
logLik(glm.true_target_parameters)
logLik(glm.target_audience)
qchisq(0.95, 7)
2*(logLik(glm.target_audience)-logLik(glm.true_target_parameters))
2*(logLik(glm.target_audience)-logLik(glm.true_target_parameters))$df
2*(logLik(glm.target_audience)-logLik(glm.true_target_parameters))[1]
2*(logLik(glm.target_audience)-logLik(glm.true_target_parameters))[2]
2*(logLik(glm.target_audience)-logLik(glm.true_target_parameters))[3]
test = rep(0,3)
test[1] = 3>1
test
df.glm_target = length(true_target_params)
# Fit regular logit for model without interactions
# Also fit model under null hypothesis (i.e. model with true parameters) for variance check
glm.target_audience <- glm(rs_targets$kpi ~ 0 + rs_targets$predictors,
family = binomial(link="logit"))
var_check.glm_target.H0 <- glm(rs_targets$kpi ~ 0 + offset(rs_targets$predictors%*%true_target_params),
family = binomial(link = "logit"))
LRT_statistic.glm_target = 2*abs(logLik(glm.target_audience) - logLik(var_check.glm_target.H0))
var_check_glm[1] = ( LRT_statistic.glm_target > qchisq(0.95, df.glm_target) )
var_check_glm
# Fit Horvitz-Thompson estimator for full sample with weights
svy_inputs = create_svyglm_inputs(full_sample$predictors, full_sample$kpi)
design_func <- svydesign(id = ~1,
data = svy_inputs$data,
weight = weights)
svy_inputs$func
svyglm.total_audience <- svyglm(formula = svy_inputs$func,
design =  design_func,
family = "quasibinomial")
regTermTest(model = svyglm.total_audience, null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")
regTermTest(model = svyglm.total_audience,
test.terms = "constant + v_audiosum + v_digitalsum + v_programsum + v_tvsum + v_vodsum + v_yousum",
null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")
regTermTest(model = svyglm.total_audience,
test.terms = ~.,
null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")
# Fit Horvitz-Thompson estimator for full sample with weights
HT_df = data.frame(x = full_sample$predictors, y = full_sample$kpi)
HT_df[x]
HT_df$x
HT_df.x
HT_df$[-y]
HT_df[,-y]
HT_df[,-"y"]
HT_df[-"y"]
HT_df[-y]
HT_df
HT_df[,-ncol(HT_df)]
svy_inputs = create_svyglm_inputs(HT_df[,-ncol(HT_df)], HT_df[,ncol(HT_df)])
design_func <- svydesign(id = ~1,
data = svy_inputs$data,
weight = weights)
svyglm.total_audience <- svyglm(formula = svy_inputs$func,
design =  design_func,
family = "quasibinomial")
design_test = svydesign(id=~1, weight = weights, data = HT_df)
svyglm_test = svyglm(formula = y~., design = design_test, family = "quasibinomial")
svy_inputs$func
svy_inputs = create_svyglm_inputs(HT_df[,-ncol(HT_df)], HT_df[,ncol(HT_df)])
svy_inputs$func
svyglm_test = svyglm(formula = svy_inputs$func., design = design_test, family = "quasibinomial")
svyglm_test = svyglm(formula = svy_inputs$func, design = design_test, family = "quasibinomial")
svy_inputs$data
design_test = svydesign(id=~1, weight = weights, data = svy_inputs$data)
svyglm_test = svyglm(formula = svy_inputs$func, design = design_test, family = "quasibinomial")
svyglm_test$coefficients
svy_inputs = create_svyglm_inputs(HT_df[,-ncol(HT_df)], HT_df[,ncol(HT_df)])
design_func <- svydesign(id = ~1,
data = svy_inputs$data,
weight = weights)
#svy_inputs = create_svyglm_inputs(HT_df[,-ncol(HT_df)], HT_df[,ncol(HT_df)])
svy_inputs = create_svyglm_inputs(full_sample$predictors, full_sample$kpi)
design_func <- svydesign(id = ~1,
data = svy_inputs$data,
weight = weights)
svyglm.total_audience <- svyglm(formula = svy_inputs$func,
design =  design_func,
family = "quasibinomial")
svyglm.total_audience$coefficients
svy_inputs$func
regTermTest(model = svyglm.total_audience,
test.terms = "~ 0 + constant + v_audiosum + v_digitalsum + v_programsum + v_tvsum + v_vodsum + v_yousum",
null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")
regTermTest(model = svyglm.total_audience,
test.terms = "~ constant + v_audiosum + v_digitalsum + v_programsum + v_tvsum + v_vodsum + v_yousum",
null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")
regTermTest(model = svyglm.total_audience,
test.terms = ~ constant + v_audiosum + v_digitalsum + v_programsum + v_tvsum + v_vodsum + v_yousum,
null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")
true_population_params
svyglm.total_audience$coefficients
N = 7500; Q = 0.5; reps = 100
# Create index of random samples for target and non-target data
idx_rs_targets = sample( 1:nrow(simulated_targets$predictors), N*Q )
idx_rs_nontargets = sample( 1:nrow(subsamples$nontarget), (N*(1-Q)) )
# Compile explanatory variables
rs_targets = rs_nontargets = list()
rs_targets$predictors = simulated_targets$predictors[idx_rs_targets,]
rs_targets$kpi = simulated_targets$kpi[idx_rs_targets]
rs_nontargets$predictors = simulated_nontargets$predictors[idx_rs_nontargets,]
rs_nontargets$kpi = simulated_nontargets$kpi[idx_rs_nontargets]
# Combine the target and non-target data into a single matrix
full_sample = list()
full_sample$predictors = rbind(rs_targets$predictors,
rs_nontargets$predictors)
full_sample$kpi = append(rs_targets$kpi,
rs_nontargets$kpi)
# Compute weights
weights = compute_weights(Q,
CPS[target_group_age, target_group_gender],
nrow(rs_targets$predictors),
nrow(rs_nontargets$predictors))
# Create data for interaction model (dependent is same as full_sample)
full_sample_w_interact = list()
interaction = rbind(rs_targets$predictors,
matrix(0,
nrow(rs_nontargets$predictors),
ncol(rs_nontargets$predictors)))
colnames(interaction) = rename_interaction_columns(colnames(interaction))
full_sample_w_interact$predictors = cbind(full_sample$predictors, interaction)
# Fit regular logit for target observations
# Also fit model under null hypothesis (i.e. model with true parameters) for variance check
glm.target_audience <- glm(rs_targets$kpi ~ 0 + rs_targets$predictors,
family = binomial(link="logit"))
var_check.glm_target.H0 <- glm(rs_targets$kpi ~ 0 + offset(rs_targets$predictors%*%true_target_params),
family = binomial(link = "logit"))
LRT_statistic.glm_target = 2*abs(logLik(glm.target_audience) - logLik(var_check.glm_target.H0))
df.glm_target = length(true_target_params)
var_check_glm[i] = ( LRT_statistic.glm_target > qchisq(0.95, df.glm_target) )
#svy_inputs = create_svyglm_inputs(HT_df[,-ncol(HT_df)], HT_df[,ncol(HT_df)])
svy_inputs = create_svyglm_inputs(full_sample$predictors, full_sample$kpi)
design_func <- svydesign(id = ~1,
data = svy_inputs$data,
weight = weights)
svyglm.total_audience <- svyglm(formula = svy_inputs$func,
design =  design_func,
family = "quasibinomial")
regTermTest(model = svyglm.total_audience,
test.terms = ~ constant + v_audiosum + v_digitalsum + v_programsum + v_tvsum + v_vodsum + v_yousum,
null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")
true_population_params
svyglm.total_audience$coefficients
abs((svyglm.total_audience$coefficients-true_population_params)/true_population_params)
100*abs((svyglm.total_audience$coefficients-true_population_params)/true_population_params)
# Check whether model rejects H0: parameter vector is DGP parameter vector (approximate LRT)
# regTermTest uses either a chi-square or a F null distribution
# df = Inf refers to denominator df, telling function to use chi-square distribution for LRT
# Approximation method is chosen to be able to deal with negative true parameters
regTermTest(model = svyglm.total_audience,
test.terms = ~ constant + v_audiosum + v_digitalsum + v_programsum + v_tvsum + v_vodsum + v_yousum,
null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")
# Check whether model rejects H0: parameter vector is DGP parameter vector (approximate LRT)
# regTermTest uses either a chi-square or a F null distribution
# df = Inf refers to denominator df, telling function to use chi-square distribution for LRT
# Approximation method is chosen to be able to deal with negative true parameters
lrt_test = regTermTest(model = svyglm.total_audience,
test.terms = ~ constant + v_audiosum + v_digitalsum + v_programsum + v_tvsum + v_vodsum + v_yousum,
null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")
lrt_test$p
# Check whether model rejects H0: parameter vector is DGP parameter vector (approximate LRT)
# regTermTest uses either a chi-square or a F null distribution
# df = Inf refers to denominator df, telling function to use chi-square distribution for LRT
# Approximation method is chosen to be able to deal with negative true parameters
regTermTest(model = svyglm.total_audience,
test.terms = ~ constant + v_audiosum + v_digitalsum + v_programsum + v_tvsum + v_vodsum + v_yousum,
null = true_population_params,
method = "LRT", df = Inf, lrt.approximation = "saddlepoint")$p
# Fit unweighted logit for model with interactions
glm.interaction_model <-  glm(full_sample$kpi ~ 0 + full_sample_w_interact$predictors,
family = binomial(link="logit"))
true_interaction_params = append(true_nontarget_params, (true_target_params-true_nontarget_params) )
var_check.glm_interaction.H0 <- glm(full_sample$kpi ~
0 + offset(full_sample_w_interact$predictors%*%true_interaction_params),
family = binomial(link = "logit"))
LRT_statistic.glm_interaction = 2*abs(logLik(glm.interaction_model) - logLik(var_check.glm_interaction.H0))
LRT_statistic.glm_interaction
df.glm_interaction = length(true_interaction_params)
df.glm_interaction
var_check.glm_interaction[i] = ( LRT_statistic.glm_interaction > qchisq(0.95, df.glm_interaction) )
var_check.glm_target = rep(0, reps)
var_check_svyglm = rep(0, reps)
var_check.glm_interaction = rep(0, reps)
var_check.glm_interaction[i] = ( LRT_statistic.glm_interaction > qchisq(0.95, df.glm_interaction) )
( LRT_statistic.glm_interaction > qchisq(0.95, df.glm_interaction) )
glm.interaction_model$coefficients
unname(glm.interaction_model$coefficients)
unname(glm.interaction_model$coefficients)[8:14]
length(glm.interaction_model$coefficients)
unname(glm.interaction_model$coefficients)[8:14]
true_interaction_params[8:14]
load("D:/brian/Documents/EUR/19-20 Business Analytics and QM/Block 3/Seminar Case Studies/Git/Seminar/simulated_target_predictors.RData")
